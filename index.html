<p><strong>איתור ותיקון שגיאות במסמך שעבר OCR</strong></p><p><strong>מגישים:</strong> אוהד גבאי ושני סמסון</p><p><strong>רקע:</strong></p><p>קיימים ברשותנו מסמכי חקיקה היסטוריים רבים בפורמטים סרוקים שעברו OCR.</p><p>לצערנו, סריקת OCR אינה מושלמת וקיימים מקרים בהם מתבצעות שגיאות בהמרה באמצעות OCR. כלומר, תוצרי ה-OCR שמתקבלים אינם נאמנים למקור, ומצויים בהם טעויות שונות. נציין לדוגמא מספר טעויות שנחשפנו אליהן במהלך המשימה.</p><ol><li>שגיאות כתיב</li><ol><li>החלפה בין כ' ל - ב': כולה -> בולה</li><li>החלפה בין ס' ל - 0: הסבר -> בולה</li><li>אותיות במקום מספרים: <img src="cid:Image_0.png" /> -> ג98ו2, 1 -> ו</li><li>החלפה בין נ' ל - 'ב: המדינה -> המדיבה</li><li>שגיאות ברישום הערות שוליים: <img src="cid:Image_1.png" /> -> התשכ"ג-1963 1 או התשכ"ג-11963 </li><li>בלבול בין "(מרכאות) לבין זוג גרשיים (' ')</li></ol><p><strong>הנחיות שימוש בתכנית:</strong></p><ol><li>הורידו ספריית קוד <u>ocrErrorDetection</u> מהgithub.</li><li>הריצו את התוכנית הראשית OcrErrorDetector.py אשר מקבלת כקלט מחרוזת של הנתיב לתיקייה בה נמצאים קבצי ה-PDF וקבצי ה- DOCX התואמים להם. </li></ol><p><u>דוגמא להרצה:</u> "python OcrErrorDetector.py "/home/username/OcrFolder</p><li>בסיום הריצה, יווצרו קבצי txt בעלי שם זהה לקבצי ה-PDF וה-DOCX. קבצים אלו יכילו את תוכן כל אחד מהחוקים בצירוף תגית <ש> לכל מילה החשודה כשגיאה.</li></ol><p>הערה: הרצנו את התכנית על גבי מערכת הפעלה של Linux.</p><p><strong>מטרת הפרויקט:</strong></p><p><u>מטרת העל:</u> איתור שגיאות במסמכים שעברו סריקה של OCR.</p><p><u>פירוט על שיטת העבודה:</u> על מנת לאתר את השגיאות במסמכים השונים ביצענו את הצעדים הבאים על מנת לאתר את החשדות בצורה המקיפה ביותר:</p><ul><li>סריקת קורפוס קבצי XML המכילים את כל החקיקה התקפה בנוסח מלא ויצירת <u>מילון המכיל מילים מתוך קבצים אלו.</u> חשוב לציין שנתנו דגש למילים בעלות משמעות להיכנס למילון שלנו ומילים המהוות סעיפים לא נכנסו. התבצע שימוש בביטויים רגולרים שונים על מנת לזהות מילים בצורה מדויקת, למשל - חילוץ מילים מתוך מרכאות וסוגריים וזיהוי תאריכים.</li></ul><li>Bigram - מעבר על המילים בזוגות. כך יכולנו לזהות מקרים בהם רצף מילים שכנות אינן תקינות</li><li>שימוש ב - hunspell: ספרייה ב-python המשמשת כמילון עברי חיצוני אשר מאתר שגיאות כתיב במילים.</li><li>שימוש ב- pytesseract: ספרייה ב-python המשמשת כ- OCR. השתמשנו בקבצי ה-PDF המקוריים, המרנו אותם לתמונות והרצנו את ה OCR הנ"ל, על מנת להשוות לקבצי ה - DOCX שקיבלנו כקלט.</li></ul><p><strong>תיאור הפרויקט במונחים של מדעי הרוח הדיגיטליים :</strong></p><p>מעבר על תוצרים של סריקות OCR מהווה פעולה ראשונית במשימה, שבה אנו קולטים את התוכן המצוי במסמכי החקיקה השונים. המשימה מתרכזת ב<u>תוכן</u> המסמכים ומנסה לאתר שגיאות הקיימות בחקיקה.</p><p>בנוסף, שימוש ב<u>מסמכים חצי מובנים</u> - קבצי XML. קבצים אלו מכילים ברובם תיוגים המסייעים לנו במציאת תוכן ספציפי שאותו נרצה לנתח, כאן כאמור התרכזנו בתוכן החוקים ועל כן חילצנו את המשפטים הכלואים בתגיות <p>, אשר מסמלות פסקאות.</p><p>יתר על כן, שימוש ב<u>מסמכים לא מובנים</u> - קבצי ה-DOCX המהווים את תוצרי ה-OCR וקבצי ה-PDF המקוריים, שאותם אף הפכנו לתמונות, על מנת להשתמש ב- pytesseract, ספריית ה-OCR בפייתון, שביצעה סריקה, נוסף על הקיים, של קבצים מתוך קורפוס החקיקה.</p><p>בעזרת ביטויים רגולריים, מילון חיצוני והמילון המבוסס על קבצי ה-XML ביצענו <u>תיוג</u> בינארי - חשד לשגיאה או לא, על כל אחת מהמילים שהופיעו בתוצרי ה-OCR.</p><p><strong>פתרון הבעיה</strong></p><p>כעת נסביר על תהליך העבודה שלנו וכיצד פעלנו על מנת למקסם את מציאת המילים החשודות כשגיאות.</p><p>שלבים מקדימים לביצוע התוכנית הראשית:</p><p>(הערה - הקבצים המבצעים זאת נמצאים בספריית הקוד)</p><ul><li>Doc2DOCX: המרת תוצרי ה-OCR בפורמט DOC לפורמט DOCX בשל התאמה עבור ספריות נוחות לשימוש בפייתון, שמסייעות בהמרת קבצים בפורמט DOCX לקבצי txt. אנחנו השתמשנו ב-docx2txt.</li></ul><li>DictionaryCreator: יצירת מילון המורכב ממילים המצויות בקבצי ה-XML. פעולה זאת נחשבת ליקרה ועל ביצענו אותה פעם אחת, ייצאנו לקובץ json ובנינו באמצעותו את המילון שנמצא בשימוש בתוכנית הראשית. מילון זה משתמש בנוסף כמונה - סוכם עבור כל מילה כמה פעמים היא מופיעה.</li></ul><p>שלבי התוכנית הראשית (OcrErrorDetector):</p><p><strong>קלט:</strong> נתיב לתיקייה המכילה קבצי PDF וקבצי DOCX.</p><p><strong>פלט:</strong> קבצי txt עבור כל חוק, אשר ימצא באותה תיקייה שניתנה כקלט.</p><ul><li>יצירת רשימה המבוססת על המילים שנלקחו מתוך סריקת ה-OCR השני עבור חוק מתוך קורפוס החקיקה.</li></ul><ul><li>המרת קובץ PDF לתמונה</li></ul><li>הפעלת הפונקציה image_to_string מתוך ספריית pytesseract לחילוץ מילים מתוך התמונה.</li><li>בניית מילון המורכב ממילים רלוונטיות בלבד על סמך סינון באמצעות ביטויים רגולרים.</li><li>המרת תוצר OCR מקובץ DOCX לקובץ txt.</li><li>מעבר על כל שורה המופיעה בקובץ txt</li><li>סינון מילים רלוונטיות על סמך ביטויים רגולרים.</li><li>עבור כל מילה -</li><ul><li>נסביר את אופן החשיבה שלנו. מאחר והמילון המבוסס על קבצי ה-XML מכיל המון מילים, הוא מורכב ממילים רבות מקבצי חקיקה מתוך הקורפוס. ומנגד יש לנו את את המילון החיצוני 	(hunspell) ורשימת מילים שנקלטו מסריקה של ה- OCR האחר. על מנת שנוכל להיעזר בכולם, הגדרנו סף (THRESHOLD) שערכו שווה ל- 10, ומגדיר שאם המילה מופיעה למעלה מ- 10 פעמים (בערך מחצית מן המילים מתוך קבצי ה-XML מופיעות עד 10 פעמים) במילון - נתייג אותה כתקינה. אחרת, ניתן למילה "הזדמנות נוספת" להיווכח שהיא תקינה - אם המילה נכתבה ללא שגיאות כתיב ונמצאת ברשימה של ה-OCR האחר.</li></ul><li>יצירת רשימת bigrams המורכבת מזוגות מילים המופיעות באותה שורה, בדרך זו נוכל לדעת האם זוג מילים שכנות מהוות זוג מילים תקינות.</li><li>כל מילה שחשודה כשגיאה - נעטוף אותה משני צידיה בתיוג <ש> (ש- שגיאה) והיא תעותק באופן הנ"ל לקובץ הפלט.</li><li>יצירת קובץ txt.</li></ul><p><strong>הערכת התוצאות:</strong></p><p>הדרך בה נמדוד את טיב התוצאות היא באמצעות מעבר מדגמי על מספר מסמכים שעברו OCR, והרצת התוכנית שלנו עליהם. בחרנו לנתח 10 קבצים שונים וקיבלנו את התוצאות להלן:</p><p><strong>False</strong></p><p><strong>True</strong></p><p>18</p><p>89</p><p><strong>Positive</strong></p><p>3</p><p><strong>Negative</strong></p><p>כעת נסביר מה כל תא בטבלה מסמל:</p><ul><li>True Positive - מספר השגיאות שהתוכנה זיהתה שהן אכן שגיאות אמיתיות.</li></ul><li>False Positive - מספר השגיאות שהתוכנה זיהתה אך הן לא באמת שגיאות.</li><li>False Negative - מספר השגיאות שקיימות בקבצים אך התוכנה לא זיהתה.</li></ul><p>תא אחד נותר ריק מאחר והוא מייצג את רוב המילים (מספר המילים התקינות שהן אכן מילים תקינות)</p><p><strong>דוגמאות:</strong></p><p><strong>מקור</strong></p><p><strong>תוצר</strong></p><p><strong>האם השגיאה אותרה?</strong></p><p>נשיא המדינה</p><p>בשיא המדיבה</p><p><strong>בשיא </strong>- לא זוהתה כשגיאה, מאחר ומילה זו קיימת במילון ה-XML.</p><p><strong>המדיבה </strong>- זוהתה כשגיאה</p><p>"על אף האמור בכל <u>חיקוק</u> לא יינתן.."</p><p>"על אף האמור בכל <u>וירקרק</u> לא יינתן.."</p><p><strong>וירקרק </strong>- זוהתה כשגיאה באמצעות המילון החיצוני, לא הופיעה במילון ה- XML.</p><p>"..דגלים וסמלים דומים.."</p><p>"..דגלים וסמלים דומים.."</p><p><strong>דגלים</strong>- מילה תקינה שזוהתה כשגיאה.</p><p>המילים "המדיבה", "וירקרק" הן שגיאות שהצלחנו לאתר (True Positive)</p><p>המילה "דגלים" הינה מילה תקינה שזוהתה כשגיאה (False Positive)</p><p>המילה "בשיא" הינה שגיאה שלא זוהתה (False Negative)</p><p><strong>מסקנות:</strong></p><ul><li>83% מתוך כלל השגיאות שהתוכנה זיהתה, הן אכן שגיאות אמיתיות</li></ul><li>קרוב ל - 90% מסך השגיאות שקיימות בקבצים זוהו ע"י התוכנה </li></ul><p>להערכנו, התוצאות שלנו בעיקר טובות כאשר מדובר במילים בעלות שגיאות כתיב, מילים שהשתבשו עם סימן פיסוק שונה מן המקור. בנוסף, ברוב המקרים אנחנו מצליחים לתפוס את השגיאה הנפוצה של הערות השוליים.</p><p>התוצאות שלנו פחות טובות עבור מילים שמספר המופעים שלהם גבוה במילון ה-XML, אך בפועל הן מהוות שגיאה במסמכים מסוימים ("בשיא"). מאחר וחסר לנו הניתוח הלוגי והתחבירי של המשפטים בחקיקה, לא נצליח לאתר שגיאות מהסוג הנ"ל.</p><p><strong>סיכום:</strong></p><p>בפרויקט זה בחרנו לעבוד עם OCR על מנת למצוא חשדות לשגיאות במסמכי חקיקה. בחרנו לשלב כמה שיטות עבודה שונות על מנת למקסם את מציאת המילים שנפגמו: שימוש במילון חיצוני, בניית מילון פנימי המבוסס על קורפוס קבצי 	ה- XML וסריקה נוספת באמצעות OCR אחר. למדנו מה זה OCR וכיצד כלי זה עובד, הכרנו ועבדנו עם ספריות שונות בפייתון כגון- docx2txt, hunspell. למדנו להשתמש בביטויים רגולרים ועל כך שהם יכולים לסייע לנו במציאת טעויות רבות בחקיקה. ובעיקר יצא לנו לחוות מקרוב את החשיבות של שימוש ב-OCR בהקשר של מדעי הרוח הדיגיטליים.</p><p>אנחנו סבורים שעמדנו במשימה עבור סוג מסוים של שגיאות, כמו שפירטנו בהערכת התוצאות, ומודעים לכך שיש גם שגיאות שלא הצלחנו לעלות עליהן.</p><p>סה"כ שמחנו לקחת חלק בקורס ולהכיר את התחומים השונים של מדעי הרוח הדיגיטליים. העבודה עם OCR הייתה מאתגרת והיינו צריכים ללמוד לזהות שגיאות שונות שלא תמיד חזרו על עצמן בין מסמכי החקיקה השונים.</p><p> </p>